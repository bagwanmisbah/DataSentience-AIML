# 🤖 Model Response Quality Scoring

This project is part of the **SSOC (Self-Supervised Open Challenges)** initiative and aims to evaluate the **quality of responses generated by Large Language Models (LLMs)** using interpretable heuristics.
[!ui](assets/image.png)
We score each response based on:
- ✅ **Completeness** — how detailed and informative the answer is
- 🙏 **Politeness** — how courteous the tone is
- 🎯 **Relevance** — how closely the response matches the input prompt

---

## 📁 Project Structure

Model Response Quality Scoring/
│
├── data/
│ ├── LLM__data.csv # Raw input data
│ └── LLM__scored_data.csv # Preprocessed data with heuristic scores
│
├── model/
│ └── response_quality_model.pkl # Trained model (optional)
│
├── heuristics.py # Scoring functions for completeness, politeness, relevance
├── preprocess.py # Applies scoring to dataset and creates training data
├── train.py # Trains a regressor to predict response quality (optional)
├── evaluate.py # Summary stats and comparison by model/language
├── predict.py # Interactive script to score a new text-response pair
└── README.md # You’re reading it now!


---

## 📊 Dataset Overview

- **File**: `LLM__data.csv`
- **Total rows**: 1,174
- **Fields**:
  - `from_language`: Language of input prompt
  - `model`: Which model generated the response (e.g., `alpha`, `beta`)
  - `text`: Prompt input
  - `response`: Model-generated reply

---

## 🔍 Heuristic Scoring Details

### ✅ Completeness
Measures length and structural richness.  
**Formula**: `min(word_count / 20, 1.0)`

### 🙏 Politeness
Checks for presence of courteous phrases.  
**Examples**: "please", "thank you", "you’re welcome"

### 🎯 Relevance
Computes overlap between prompt and response using token intersection (Jaccard-like).

---

## 🚀 How to Run the Project

### 1. Preprocess the Data
```bash
python preprocess.py

python evaluate.py
python train.py
python predict.py
Enter input text: How do I cook pasta?
Enter model response: Sure! Boil water, add salt and pasta. Cook for 8–10 mins, then drain.
🔍 Heuristic Scores:
Completeness: 0.85
Politeness:   0.00
Relevance:    0.80
⭐ Overall Quality Score: 0.73
